{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import time\n",
    "\n",
    "def generate_url(jobTitle,location):\n",
    "    \"\"\"Generate URL given job title and location\"\"\"\n",
    "    url = f\"https://ca.indeed.com/{jobTitle}-jobs-in-{location}\"\n",
    "    return url\n",
    "\n",
    "def get_record(card):\n",
    "    \"\"\"Extract info from one job card\"\"\"\n",
    "    \n",
    "    atag = card.h2.a\n",
    "    jobTitle = atag.get('title')\n",
    "    jobURL = \"http://indeed.com\" + atag.get('href')\n",
    "    jobCompany = card.find('span',class_='company').text.strip()\n",
    "    \n",
    "    # for job location, sometimes it's <span> sometimes it's <div> \n",
    "    if card.find('span',class_='location'):\n",
    "        jobLocation = card.find('span',class_='location').text.strip()\n",
    "    else:\n",
    "        jobLocation = card.find('div',class_='location').text.strip()\n",
    "        \n",
    "    jobSummary = card.find('div','summary').text.strip()\n",
    "    jobPostDate = card.find('span','date').text\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # sometimes there's salary\n",
    "    if card.find('span','salaryText'):\n",
    "        jobSalary = card.find('span','salaryText').text.strip() \n",
    "    else:\n",
    "        jobSalary = ''\n",
    "        \n",
    "    job = (jobTitle,jobCompany,jobLocation,jobPostDate,today,jobSalary,jobSummary,jobURL)\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "job_title = \"\"  # empty string for all jobs\n",
    "loc = \"ontario\"\n",
    "url = generate_url(jobTitle = job_title, location = loc)\n",
    "\n",
    "driver = webdriver.Chrome(\"/Users/Traky/Desktop/jn/chromedriver\")\n",
    "\n",
    "# there will be pop-ups but that doesn't matter\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    driver.get(url)\n",
    "\n",
    "    # wait for human resolving a captcha\n",
    "    #### multiple captcha... this block needs update \n",
    "    try: \n",
    "        captcha = driver.find_element_by_css_selector('iframe[role=presentation]')\n",
    "        driver.switch_to.frame(captcha)\n",
    "        wait = WebDriverWait(driver, 6000)  # wait 10 mins\n",
    "        try:\n",
    "            wait.until(ec.presence_of_element_located(('css selector', 'span[aria-checked=\"true\"]')))\n",
    "        except TimeoutException:\n",
    "            print('\\nTime out')\n",
    "    except: \n",
    "        print('\\nCaptcha solved successfully, proceeding to click!')\n",
    "        driver.switch_to.parent_frame()\n",
    "        driver.find_element_by_css_selector('#recaptcha-demo-submit').click()\n",
    "\n",
    "    # make soup\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    cards = soup.find_all('div',class_='jobsearch-SerpJobCard')\n",
    "    \n",
    "    for card in cards: \n",
    "        record = get_record(card)\n",
    "        records.append(record)    # append tuple to list\n",
    "        \n",
    "    try:\n",
    "        url = \"https://ca.indeed.com\" + soup.find('a',{'aria-label':'Next'}).get('href')\n",
    "    except AttributeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [jobTitle, jobCompany, jobLocation, jobPostDate, today, jobSalary, jobSummary, jobURL]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>jobTitle</th>\n      <th>jobCompany</th>\n      <th>jobLocation</th>\n      <th>jobPostDate</th>\n      <th>today</th>\n      <th>jobSalary</th>\n      <th>jobSummary</th>\n      <th>jobURL</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# make dataframe \n",
    "records_df = pd.DataFrame(records, columns =['jobTitle','jobCompany','jobLocation','jobPostDate','today','jobSalary','jobSummary','jobURL']) \n",
    "\n",
    "records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "records_df.to_csv(\"data/\"+job_title+\"_in_\"+loc+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}